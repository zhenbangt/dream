Env ID: [220]
================================================================================
Timestep: 0
State: tensor([4, 4, 0], dtype=torch.int32)
Action: right
Reward: -0.0853487029671669
Distance: 6.551321983337402
Next state: tensor([5, 4, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1], dtype=torch.int32)
Action: ride_bus
Reward: -0.00010929256677627563
Distance: 6.536670684814453
Next state: tensor([8, 7, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 2
State: tensor([8, 7, 1], dtype=torch.int32)
Action: right
Reward: 0.02875795215368271
Distance: 6.436779975891113
Next state: tensor([8, 7, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 3
State: tensor([8, 7, 1], dtype=torch.int32)
Action: up
Reward: -0.20400676131248474
Distance: 6.3080220222473145
Next state: tensor([8, 8, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 4
State: tensor([8, 8, 0], dtype=torch.int32)
Action: end_episode
Reward: -0.16581830382347107
Distance: 6.412028789520264
Next state: tensor([8, 8, 0], dtype=torch.int32)
================================================================================

