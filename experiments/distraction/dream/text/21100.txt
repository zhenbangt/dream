Env ID: [110]
================================================================================
Timestep: 0
State: tensor([4, 4, 0], dtype=torch.int32)
Action: right
Reward: -0.05284843593835831
Distance: 9.031787872314453
Next state: tensor([5, 4, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1], dtype=torch.int32)
Action: ride_bus
Reward: 0.1206459030508995
Distance: 8.984636306762695
Next state: tensor([0, 7, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 2
State: tensor([0, 7, 1], dtype=torch.int32)
Action: left
Reward: -0.34596118330955505
Distance: 8.76399040222168
Next state: tensor([0, 7, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 3
State: tensor([0, 7, 1], dtype=torch.int32)
Action: end_episode
Reward: -0.01191578060388565
Distance: 9.0099515914917
Next state: tensor([0, 7, 1], dtype=torch.int32)
================================================================================

