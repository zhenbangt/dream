Env ID: [44]
================================================================================
Timestep: 0
State: tensor([4, 4, 0], dtype=torch.int32)
Action: right
Reward: -0.24231204390525818
Distance: 8.552596092224121
Next state: tensor([5, 4, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1], dtype=torch.int32)
Action: pickup
Reward: -0.09828529506921768
Distance: 8.694908142089844
Next state: tensor([5, 4, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1], dtype=torch.int32)
Action: right
Reward: 0.04596080631017685
Distance: 8.693193435668945
Next state: tensor([6, 4, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 4, 0], dtype=torch.int32)
Action: ride_bus
Reward: -0.2388816773891449
Distance: 8.547232627868652
Next state: tensor([6, 4, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 4
State: tensor([6, 4, 0], dtype=torch.int32)
Action: down
Reward: -0.21322688460350037
Distance: 8.686114311218262
Next state: tensor([6, 3, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 5
State: tensor([6, 3, 0], dtype=torch.int32)
Action: right
Reward: -0.44494590163230896
Distance: 8.799341201782227
Next state: tensor([7, 3, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 6
State: tensor([7, 3, 0], dtype=torch.int32)
Action: drop
Reward: -0.423226922750473
Distance: 9.144287109375
Next state: tensor([7, 3, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 7
State: tensor([7, 3, 0], dtype=torch.int32)
Action: left
Reward: -0.5195060968399048
Distance: 9.467514038085938
Next state: tensor([6, 3, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 8
State: tensor([6, 3, 0], dtype=torch.int32)
Action: end_episode
Reward: -0.09233532100915909
Distance: 9.887020111083984
Next state: tensor([6, 3, 0], dtype=torch.int32)
================================================================================

