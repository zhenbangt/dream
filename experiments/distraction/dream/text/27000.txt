Env ID: [110]
================================================================================
Timestep: 0
State: tensor([4, 4, 0], dtype=torch.int32)
Action: right
Reward: -0.08175430446863174
Distance: 9.072425842285156
Next state: tensor([5, 4, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1], dtype=torch.int32)
Action: ride_bus
Reward: 0.1677030622959137
Distance: 9.054180145263672
Next state: tensor([0, 7, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 2
State: tensor([0, 7, 1], dtype=torch.int32)
Action: pickup
Reward: -0.19256648421287537
Distance: 8.786477088928223
Next state: tensor([0, 7, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 3
State: tensor([0, 7, 1], dtype=torch.int32)
Action: end_episode
Reward: -0.47607383131980896
Distance: 8.879043579101562
Next state: tensor([0, 7, 1], dtype=torch.int32)
================================================================================

