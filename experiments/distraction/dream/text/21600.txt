Env ID: [319]
================================================================================
Timestep: 0
State: tensor([4, 4, 0], dtype=torch.int32)
Action: right
Reward: -0.04383239895105362
Distance: 7.656855583190918
Next state: tensor([5, 4, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1], dtype=torch.int32)
Action: down
Reward: -0.013515569269657135
Distance: 7.6006879806518555
Next state: tensor([5, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 1], dtype=torch.int32)
Action: left
Reward: -0.0157991424202919
Distance: 7.5142035484313965
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 1], dtype=torch.int32)
Action: down
Reward: 0.0022019371390342712
Distance: 7.430002689361572
Next state: tensor([4, 2, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0], dtype=torch.int32)
Action: pickup
Reward: -0.36561307311058044
Distance: 7.327800750732422
Next state: tensor([4, 2, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0], dtype=torch.int32)
Action: left
Reward: 0.11701478809118271
Distance: 7.593413829803467
Next state: tensor([3, 2, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 0], dtype=torch.int32)
Action: down
Reward: 0.002860449254512787
Distance: 7.376399040222168
Next state: tensor([3, 1, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 1, 0], dtype=torch.int32)
Action: drop
Reward: -0.5349289178848267
Distance: 7.273538589477539
Next state: tensor([3, 1, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 1, 0], dtype=torch.int32)
Action: drop
Reward: -0.9265543222427368
Distance: 7.708467483520508
Next state: tensor([3, 1, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 1, 0], dtype=torch.int32)
Action: left
Reward: -0.5638967752456665
Distance: 8.535021781921387
Next state: tensor([2, 1, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 10
State: tensor([2, 1, 0], dtype=torch.int32)
Action: right
Reward: -0.43749770522117615
Distance: 8.998918533325195
Next state: tensor([3, 1, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 11
State: tensor([3, 1, 0], dtype=torch.int32)
Action: right
Reward: -0.1501213014125824
Distance: 9.336416244506836
Next state: tensor([4, 1, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 12
State: tensor([4, 1, 0], dtype=torch.int32)
Action: drop
Reward: -0.44120749831199646
Distance: 9.386537551879883
Next state: tensor([4, 1, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 13
State: tensor([4, 1, 0], dtype=torch.int32)
Action: left
Reward: 0.306326299905777
Distance: 9.727745056152344
Next state: tensor([3, 1, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 14
State: tensor([3, 1, 0], dtype=torch.int32)
Action: end_episode
Reward: 0.2437366545200348
Distance: 9.321418762207031
Next state: tensor([3, 1, 0], dtype=torch.int32)
================================================================================

