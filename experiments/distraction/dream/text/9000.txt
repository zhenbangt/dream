Env ID: [132]
================================================================================
Timestep: 0
State: tensor([4, 4, 0], dtype=torch.int32)
Action: down
Reward: -0.22273215651512146
Distance: 8.400995254516602
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 3, 1], dtype=torch.int32)
Action: right
Reward: -0.14083155989646912
Distance: 8.523727416992188
Next state: tensor([5, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 3, 1], dtype=torch.int32)
Action: left
Reward: -0.0032907500863075256
Distance: 8.564558982849121
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 1], dtype=torch.int32)
Action: right
Reward: -0.06760940700769424
Distance: 8.467849731445312
Next state: tensor([5, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 3, 1], dtype=torch.int32)
Action: end_episode
Reward: -0.20744475722312927
Distance: 8.43545913696289
Next state: tensor([5, 3, 1], dtype=torch.int32)
================================================================================

