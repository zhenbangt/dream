Env ID: [286]
================================================================================
Timestep: 0
State: tensor([4, 4, 0], dtype=torch.int32)
Action: right
Reward: -0.08589134365320206
Distance: 8.534543991088867
Next state: tensor([5, 4, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1], dtype=torch.int32)
Action: ride_bus
Reward: -0.14131125807762146
Distance: 8.520435333251953
Next state: tensor([8, 1, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 2
State: tensor([8, 1, 1], dtype=torch.int32)
Action: end_episode
Reward: -0.06977234035730362
Distance: 8.561746597290039
Next state: tensor([8, 1, 1], dtype=torch.int32)
================================================================================

