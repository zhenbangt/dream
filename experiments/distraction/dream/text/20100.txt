Env ID: [286]
================================================================================
Timestep: 0
State: tensor([4, 4, 0], dtype=torch.int32)
Action: end_episode
Reward: -0.021812058985233307
Distance: 8.202926635742188
Next state: tensor([4, 4, 0], dtype=torch.int32)
================================================================================

