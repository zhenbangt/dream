Env ID: [572]
================================================================================
Timestep: 0
State: tensor([4, 4, 0], dtype=torch.int32)
Action: noop
Reward: -0.06620941311120987
Distance: 9.38595962524414
Next state: tensor([4, 4, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0], dtype=torch.int32)
Action: drop
Reward: -0.2038951814174652
Distance: 9.352169036865234
Next state: tensor([4, 4, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0], dtype=torch.int32)
Action: right
Reward: 0.01164092868566513
Distance: 9.456064224243164
Next state: tensor([5, 4, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1], dtype=torch.int32)
Action: down
Reward: 0.10562076419591904
Distance: 9.344423294067383
Next state: tensor([5, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 3, 1], dtype=torch.int32)
Action: left
Reward: -0.3042474687099457
Distance: 9.138802528381348
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 1], dtype=torch.int32)
Action: drop
Reward: 0.20329514145851135
Distance: 9.343050003051758
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 1], dtype=torch.int32)
Action: ride_bus
Reward: 0.4326461851596832
Distance: 9.039754867553711
Next state: tensor([8, 1, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 7
State: tensor([8, 1, 1], dtype=torch.int32)
Action: ride_bus
Reward: -0.7070928812026978
Distance: 8.507108688354492
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 3, 1], dtype=torch.int32)
Action: pickup
Reward: -0.42746028304100037
Distance: 9.114201545715332
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 3, 1], dtype=torch.int32)
Action: drop
Reward: -0.21535643935203552
Distance: 9.441661834716797
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 10
State: tensor([4, 3, 1], dtype=torch.int32)
Action: drop
Reward: -0.16663798689842224
Distance: 9.557018280029297
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 11
State: tensor([4, 3, 1], dtype=torch.int32)
Action: drop
Reward: -0.1114870086312294
Distance: 9.623656272888184
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 12
State: tensor([4, 3, 1], dtype=torch.int32)
Action: drop
Reward: -0.12692221999168396
Distance: 9.635143280029297
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 13
State: tensor([4, 3, 1], dtype=torch.int32)
Action: drop
Reward: -0.12166271358728409
Distance: 9.662065505981445
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 14
State: tensor([4, 3, 1], dtype=torch.int32)
Action: drop
Reward: -0.1159263625741005
Distance: 9.683728218078613
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 15
State: tensor([4, 3, 1], dtype=torch.int32)
Action: drop
Reward: -0.10628185421228409
Distance: 9.699654579162598
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 16
State: tensor([4, 3, 1], dtype=torch.int32)
Action: up
Reward: -0.35808905959129333
Distance: 9.705936431884766
Next state: tensor([4, 4, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 17
State: tensor([4, 4, 0], dtype=torch.int32)
Action: down
Reward: 0.054041288793087006
Distance: 9.964025497436523
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 18
State: tensor([4, 3, 1], dtype=torch.int32)
Action: drop
Reward: -0.21212348341941833
Distance: 9.80998420715332
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 19
State: tensor([4, 3, 1], dtype=torch.int32)
Action: up
Reward: -0.16578158736228943
Distance: 9.922107696533203
Next state: tensor([4, 4, 0], dtype=torch.int32)
================================================================================

