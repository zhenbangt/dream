Env ID: [0]
================================================================================
Timestep: 0
State: tensor([4, 4, 0], dtype=torch.int32)
Action: drop
Reward: 0.15643158555030823
Distance: 8.433794021606445
Next state: tensor([4, 4, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0], dtype=torch.int32)
Action: down
Reward: -0.117559053003788
Distance: 8.177362442016602
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 3, 1], dtype=torch.int32)
Action: pickup
Reward: -0.16000232100486755
Distance: 8.194921493530273
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 1], dtype=torch.int32)
Action: pickup
Reward: -0.21793612837791443
Distance: 8.254923820495605
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 1], dtype=torch.int32)
Action: down
Reward: 0.011438749730587006
Distance: 8.372859954833984
Next state: tensor([4, 2, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0], dtype=torch.int32)
Action: end_episode
Reward: 0.11538257449865341
Distance: 8.261421203613281
Next state: tensor([4, 2, 0], dtype=torch.int32)
================================================================================

