Env ID: [55]
================================================================================
Timestep: 0
State: tensor([4, 4, 0], dtype=torch.int32)
Action: left
Reward: -0.18304786086082458
Distance: 8.739599227905273
Next state: tensor([3, 4, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 4, 1], dtype=torch.int32)
Action: left
Reward: 0.08584632724523544
Distance: 8.822647094726562
Next state: tensor([2, 4, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 4, 0], dtype=torch.int32)
Action: down
Reward: -0.22305259108543396
Distance: 8.636800765991211
Next state: tensor([2, 3, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 3, 0], dtype=torch.int32)
Action: down
Reward: 0.049181364476680756
Distance: 8.75985336303711
Next state: tensor([2, 2, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0], dtype=torch.int32)
Action: down
Reward: -0.39489707350730896
Distance: 8.610671997070312
Next state: tensor([2, 1, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 1, 0], dtype=torch.int32)
Action: drop
Reward: -0.371652215719223
Distance: 8.905569076538086
Next state: tensor([2, 1, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 1, 0], dtype=torch.int32)
Action: drop
Reward: -0.19270095229148865
Distance: 9.177221298217773
Next state: tensor([2, 1, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 0], dtype=torch.int32)
Action: pickup
Reward: -0.2503429353237152
Distance: 9.269922256469727
Next state: tensor([2, 1, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 1, 0], dtype=torch.int32)
Action: end_episode
Reward: -0.3347354829311371
Distance: 9.420265197753906
Next state: tensor([2, 1, 0], dtype=torch.int32)
================================================================================

