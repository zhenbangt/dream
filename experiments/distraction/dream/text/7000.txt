Env ID: [11]
================================================================================
Timestep: 0
State: tensor([4, 4, 0], dtype=torch.int32)
Action: drop
Reward: -0.08513031154870987
Distance: 6.307319641113281
Next state: tensor([4, 4, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0], dtype=torch.int32)
Action: down
Reward: -0.16803798079490662
Distance: 6.292449951171875
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 3, 1], dtype=torch.int32)
Action: left
Reward: -0.23336610198020935
Distance: 6.360487937927246
Next state: tensor([3, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 3, 1], dtype=torch.int32)
Action: down
Reward: -0.1070776954293251
Distance: 6.49385404586792
Next state: tensor([3, 2, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 0], dtype=torch.int32)
Action: end_episode
Reward: -0.12327823787927628
Distance: 6.500931739807129
Next state: tensor([3, 2, 0], dtype=torch.int32)
================================================================================

