Env ID: [220]
================================================================================
Timestep: 0
State: tensor([4, 4, 0], dtype=torch.int32)
Action: right
Reward: -0.08143100887537003
Distance: 8.015201568603516
Next state: tensor([5, 4, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1], dtype=torch.int32)
Action: right
Reward: -0.05064401775598526
Distance: 7.9966325759887695
Next state: tensor([6, 4, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0], dtype=torch.int32)
Action: left
Reward: -0.1974411904811859
Distance: 7.947276592254639
Next state: tensor([5, 4, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1], dtype=torch.int32)
Action: down
Reward: -0.32397517561912537
Distance: 8.044717788696289
Next state: tensor([5, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 4
State: tensor([5, 3, 1], dtype=torch.int32)
Action: drop
Reward: -0.02691517025232315
Distance: 8.268692970275879
Next state: tensor([5, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 3, 1], dtype=torch.int32)
Action: pickup
Reward: -0.02328643947839737
Distance: 8.195608139038086
Next state: tensor([5, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 6
State: tensor([5, 3, 1], dtype=torch.int32)
Action: end_episode
Reward: -0.018293000757694244
Distance: 8.118894577026367
Next state: tensor([5, 3, 1], dtype=torch.int32)
================================================================================

