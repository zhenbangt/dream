Env ID: [495]
================================================================================
Timestep: 0
State: tensor([4, 4, 0], dtype=torch.int32)
Action: up
Reward: -0.01954517513513565
Distance: 4.455519676208496
Next state: tensor([4, 5, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 1], dtype=torch.int32)
Action: ride_bus
Reward: 0.0450681671500206
Distance: 4.375064849853516
Next state: tensor([8, 1, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 2
State: tensor([8, 1, 1], dtype=torch.int32)
Action: left
Reward: -0.25085124373435974
Distance: 4.229996681213379
Next state: tensor([7, 1, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 3
State: tensor([7, 1, 0], dtype=torch.int32)
Action: end_episode
Reward: 0.09420862048864365
Distance: 4.380847930908203
Next state: tensor([7, 1, 0], dtype=torch.int32)
================================================================================

