Env ID: [77]
================================================================================
Timestep: 0
State: tensor([4, 4, 0], dtype=torch.int32)
Action: down
Reward: 0.6634191274642944
Distance: 10.104998588562012
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 3, 1], dtype=torch.int32)
Action: down
Reward: -0.03460083156824112
Distance: 9.34157943725586
Next state: tensor([4, 2, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0], dtype=torch.int32)
Action: down
Reward: -0.10774192959070206
Distance: 9.276180267333984
Next state: tensor([4, 1, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 1, 0], dtype=torch.int32)
Action: up
Reward: -0.0908123031258583
Distance: 9.28392219543457
Next state: tensor([4, 2, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0], dtype=torch.int32)
Action: end_episode
Reward: -0.0779930129647255
Distance: 9.274734497070312
Next state: tensor([4, 2, 0], dtype=torch.int32)
================================================================================

