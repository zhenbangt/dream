Env ID: [396]
================================================================================
Timestep: 0
State: tensor([4, 4, 0], dtype=torch.int32)
Action: pickup
Reward: -0.06126747280359268
Distance: 7.836848258972168
Next state: tensor([4, 4, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0], dtype=torch.int32)
Action: right
Reward: -0.14166030287742615
Distance: 7.7981157302856445
Next state: tensor([5, 4, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1], dtype=torch.int32)
Action: right
Reward: -0.14938697218894958
Distance: 7.839776039123535
Next state: tensor([6, 4, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 3
State: tensor([6, 4, 0], dtype=torch.int32)
Action: right
Reward: -0.12060890346765518
Distance: 7.889163017272949
Next state: tensor([7, 4, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 4
State: tensor([7, 4, 0], dtype=torch.int32)
Action: end_episode
Reward: -0.0897737517952919
Distance: 7.909771919250488
Next state: tensor([7, 4, 0], dtype=torch.int32)
================================================================================

