Env ID: [440]
================================================================================
Timestep: 0
State: tensor([4, 4, 0], dtype=torch.int32)
Action: ride_bus
Reward: -0.07200679928064346
Distance: 8.24767017364502
Next state: tensor([4, 4, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0], dtype=torch.int32)
Action: right
Reward: -0.08976421505212784
Distance: 8.219676971435547
Next state: tensor([5, 4, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1], dtype=torch.int32)
Action: left
Reward: -0.10448799282312393
Distance: 8.209441184997559
Next state: tensor([4, 4, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 4, 0], dtype=torch.int32)
Action: left
Reward: -0.03398952633142471
Distance: 8.213929176330566
Next state: tensor([3, 4, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 4, 1], dtype=torch.int32)
Action: up
Reward: -0.13842925429344177
Distance: 8.147918701171875
Next state: tensor([3, 5, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 5, 1], dtype=torch.int32)
Action: pickup
Reward: -0.07100830227136612
Distance: 8.186347961425781
Next state: tensor([3, 5, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 5, 1], dtype=torch.int32)
Action: pickup
Reward: -0.05896148830652237
Distance: 8.157356262207031
Next state: tensor([3, 5, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 5, 1], dtype=torch.int32)
Action: pickup
Reward: -0.1804557740688324
Distance: 8.116317749023438
Next state: tensor([3, 5, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 5, 1], dtype=torch.int32)
Action: pickup
Reward: -0.14850959181785583
Distance: 8.196773529052734
Next state: tensor([3, 5, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 5, 1], dtype=torch.int32)
Action: pickup
Reward: -0.1105113998055458
Distance: 8.245283126831055
Next state: tensor([3, 5, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 10
State: tensor([3, 5, 1], dtype=torch.int32)
Action: pickup
Reward: -0.08857116848230362
Distance: 8.255794525146484
Next state: tensor([3, 5, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 11
State: tensor([3, 5, 1], dtype=torch.int32)
Action: pickup
Reward: -0.06210670620203018
Distance: 8.244365692138672
Next state: tensor([3, 5, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 12
State: tensor([3, 5, 1], dtype=torch.int32)
Action: pickup
Reward: -0.08621082454919815
Distance: 8.206472396850586
Next state: tensor([3, 5, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 13
State: tensor([3, 5, 1], dtype=torch.int32)
Action: pickup
Reward: -0.09249649196863174
Distance: 8.192683219909668
Next state: tensor([3, 5, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 14
State: tensor([3, 5, 1], dtype=torch.int32)
Action: pickup
Reward: -0.08966980129480362
Distance: 8.185179710388184
Next state: tensor([3, 5, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 15
State: tensor([3, 5, 1], dtype=torch.int32)
Action: pickup
Reward: -0.0787273421883583
Distance: 8.174849510192871
Next state: tensor([3, 5, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 16
State: tensor([3, 5, 1], dtype=torch.int32)
Action: pickup
Reward: -0.061304666101932526
Distance: 8.153576850891113
Next state: tensor([3, 5, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 17
State: tensor([3, 5, 1], dtype=torch.int32)
Action: pickup
Reward: -0.0882793441414833
Distance: 8.11488151550293
Next state: tensor([3, 5, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 18
State: tensor([3, 5, 1], dtype=torch.int32)
Action: pickup
Reward: -0.1130138412117958
Distance: 8.103160858154297
Next state: tensor([3, 5, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 19
State: tensor([3, 5, 1], dtype=torch.int32)
Action: pickup
Reward: -0.13278159499168396
Distance: 8.116174697875977
Next state: tensor([3, 5, 1], dtype=torch.int32)
================================================================================

