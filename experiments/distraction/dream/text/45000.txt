Env ID: [418]
================================================================================
Timestep: 0
State: tensor([4, 4, 0], dtype=torch.int32)
Action: ride_bus
Reward: -0.19439849257469177
Distance: 9.700370788574219
Next state: tensor([4, 4, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0], dtype=torch.int32)
Action: ride_bus
Reward: -0.161442369222641
Distance: 9.794769287109375
Next state: tensor([4, 4, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0], dtype=torch.int32)
Action: down
Reward: 0.04818858951330185
Distance: 9.85621166229248
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 1], dtype=torch.int32)
Action: ride_bus
Reward: 0.8008922338485718
Distance: 9.708023071289062
Next state: tensor([8, 1, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 4
State: tensor([8, 1, 1], dtype=torch.int32)
Action: ride_bus
Reward: -0.0942750945687294
Distance: 8.807130813598633
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 1], dtype=torch.int32)
Action: up
Reward: -0.23867473006248474
Distance: 8.801405906677246
Next state: tensor([4, 4, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 4, 0], dtype=torch.int32)
Action: ride_bus
Reward: -0.3568664491176605
Distance: 8.940080642700195
Next state: tensor([4, 4, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 4, 0], dtype=torch.int32)
Action: ride_bus
Reward: -0.23867091536521912
Distance: 9.19694709777832
Next state: tensor([4, 4, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0], dtype=torch.int32)
Action: down
Reward: 0.8865264654159546
Distance: 9.335618019104004
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 3, 1], dtype=torch.int32)
Action: right
Reward: -0.22089633345603943
Distance: 8.349091529846191
Next state: tensor([5, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 10
State: tensor([5, 3, 1], dtype=torch.int32)
Action: left
Reward: -0.32924994826316833
Distance: 8.469987869262695
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 11
State: tensor([4, 3, 1], dtype=torch.int32)
Action: drop
Reward: -0.3646465241909027
Distance: 8.699237823486328
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 12
State: tensor([4, 3, 1], dtype=torch.int32)
Action: right
Reward: -0.09242210537195206
Distance: 8.963884353637695
Next state: tensor([5, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 13
State: tensor([5, 3, 1], dtype=torch.int32)
Action: left
Reward: -0.7563415765762329
Distance: 8.956306457519531
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 14
State: tensor([4, 3, 1], dtype=torch.int32)
Action: drop
Reward: -0.11965904384851456
Distance: 9.612648010253906
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 15
State: tensor([4, 3, 1], dtype=torch.int32)
Action: up
Reward: 0.022895239293575287
Distance: 9.632307052612305
Next state: tensor([4, 4, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 16
State: tensor([4, 4, 0], dtype=torch.int32)
Action: ride_bus
Reward: -0.5738493204116821
Distance: 9.509411811828613
Next state: tensor([4, 4, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 17
State: tensor([4, 4, 0], dtype=torch.int32)
Action: down
Reward: 0.8331226110458374
Distance: 9.983261108398438
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 18
State: tensor([4, 3, 1], dtype=torch.int32)
Action: up
Reward: -1.0362945795059204
Distance: 9.050138473510742
Next state: tensor([4, 4, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 19
State: tensor([4, 4, 0], dtype=torch.int32)
Action: right
Reward: -0.16034182906150818
Distance: 9.986433029174805
Next state: tensor([5, 4, 1], dtype=torch.int32)
================================================================================

