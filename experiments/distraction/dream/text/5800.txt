Env ID: [572]
================================================================================
Timestep: 0
State: tensor([4, 4, 0], dtype=torch.int32)
Action: up
Reward: -0.21505174040794373
Distance: 7.4647135734558105
Next state: tensor([4, 5, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 1], dtype=torch.int32)
Action: noop
Reward: -0.09730110317468643
Distance: 7.579765319824219
Next state: tensor([4, 5, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 5, 1], dtype=torch.int32)
Action: right
Reward: 0.05311717838048935
Distance: 7.577066421508789
Next state: tensor([5, 5, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 5, 1], dtype=torch.int32)
Action: end_episode
Reward: 0.009888075292110443
Distance: 7.423949241638184
Next state: tensor([5, 5, 1], dtype=torch.int32)
================================================================================

