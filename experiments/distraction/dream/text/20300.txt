Env ID: [198]
================================================================================
Timestep: 0
State: tensor([4, 4, 0], dtype=torch.int32)
Action: noop
Reward: -0.036431409418582916
Distance: 7.792393684387207
Next state: tensor([4, 4, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0], dtype=torch.int32)
Action: right
Reward: -0.16392287611961365
Distance: 7.728825092315674
Next state: tensor([5, 4, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 2
State: tensor([5, 4, 1], dtype=torch.int32)
Action: ride_bus
Reward: 0.5798243284225464
Distance: 7.792747974395752
Next state: tensor([0, 1, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 3
State: tensor([0, 1, 1], dtype=torch.int32)
Action: end_episode
Reward: 0.04435767978429794
Distance: 7.112923622131348
Next state: tensor([0, 1, 1], dtype=torch.int32)
================================================================================

