Env ID: [253]
================================================================================
Timestep: 0
State: tensor([4, 4, 0], dtype=torch.int32)
Action: noop
Reward: -0.1538287103176117
Distance: 4.65164041519165
Next state: tensor([4, 4, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0], dtype=torch.int32)
Action: down
Reward: -0.089971162378788
Distance: 4.705469131469727
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 3, 1], dtype=torch.int32)
Action: ride_bus
Reward: 0.2841595709323883
Distance: 4.695440292358398
Next state: tensor([0, 7, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 3
State: tensor([0, 7, 1], dtype=torch.int32)
Action: end_episode
Reward: -0.10287056118249893
Distance: 4.311280727386475
Next state: tensor([0, 7, 1], dtype=torch.int32)
================================================================================

