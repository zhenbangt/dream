Env ID: [220]
================================================================================
Timestep: 0
State: tensor([4, 4, 0], dtype=torch.int32)
Action: down
Reward: -0.1807475984096527
Distance: 6.374967575073242
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 3, 1], dtype=torch.int32)
Action: up
Reward: -0.14315804839134216
Distance: 6.455715179443359
Next state: tensor([4, 4, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0], dtype=torch.int32)
Action: end_episode
Reward: 0.013738535344600677
Distance: 6.498873233795166
Next state: tensor([4, 4, 0], dtype=torch.int32)
================================================================================

