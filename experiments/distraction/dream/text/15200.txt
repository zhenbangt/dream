Env ID: [77]
================================================================================
Timestep: 0
State: tensor([4, 4, 0], dtype=torch.int32)
Action: right
Reward: -0.15821513533592224
Distance: 7.520810127258301
Next state: tensor([5, 4, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1], dtype=torch.int32)
Action: ride_bus
Reward: 0.22902527451515198
Distance: 7.5790252685546875
Next state: tensor([8, 7, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 2
State: tensor([8, 7, 1], dtype=torch.int32)
Action: down
Reward: -0.10540971904993057
Distance: 7.25
Next state: tensor([8, 6, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 3
State: tensor([8, 6, 0], dtype=torch.int32)
Action: end_episode
Reward: -0.41033849120140076
Distance: 7.2554097175598145
Next state: tensor([8, 6, 0], dtype=torch.int32)
================================================================================

