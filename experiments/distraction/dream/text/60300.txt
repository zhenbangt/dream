Env ID: [132]
================================================================================
Timestep: 0
State: tensor([4, 4, 0], dtype=torch.int32)
Action: noop
Reward: -0.14769229292869568
Distance: 9.245633125305176
Next state: tensor([4, 4, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0], dtype=torch.int32)
Action: noop
Reward: -0.06445655971765518
Distance: 9.293325424194336
Next state: tensor([4, 4, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0], dtype=torch.int32)
Action: down
Reward: 0.0011638626456260681
Distance: 9.257781982421875
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 1], dtype=torch.int32)
Action: end_episode
Reward: -0.2912660539150238
Distance: 9.156618118286133
Next state: tensor([4, 3, 1], dtype=torch.int32)
================================================================================

