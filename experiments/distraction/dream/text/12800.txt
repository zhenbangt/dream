Env ID: [352]
================================================================================
Timestep: 0
State: tensor([4, 4, 0], dtype=torch.int32)
Action: right
Reward: -0.021278001368045807
Distance: 8.120811462402344
Next state: tensor([5, 4, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1], dtype=torch.int32)
Action: ride_bus
Reward: 0.017352961003780365
Distance: 8.042089462280273
Next state: tensor([8, 7, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 2
State: tensor([8, 7, 1], dtype=torch.int32)
Action: down
Reward: 0.0883273109793663
Distance: 7.924736499786377
Next state: tensor([8, 6, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 3
State: tensor([8, 6, 0], dtype=torch.int32)
Action: ride_bus
Reward: -0.16888484358787537
Distance: 7.7364091873168945
Next state: tensor([8, 6, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 4
State: tensor([8, 6, 0], dtype=torch.int32)
Action: end_episode
Reward: -0.20358619093894958
Distance: 7.805294036865234
Next state: tensor([8, 6, 0], dtype=torch.int32)
================================================================================

