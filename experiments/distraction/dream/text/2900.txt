Env ID: [539]
================================================================================
Timestep: 0
State: tensor([4, 4, 0], dtype=torch.int32)
Action: noop
Reward: 0.00236501544713974
Distance: 7.91366720199585
Next state: tensor([4, 4, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0], dtype=torch.int32)
Action: left
Reward: -0.037082768976688385
Distance: 7.811302185058594
Next state: tensor([3, 4, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 4, 1], dtype=torch.int32)
Action: up
Reward: -0.03836069256067276
Distance: 7.748384952545166
Next state: tensor([3, 5, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 5, 1], dtype=torch.int32)
Action: drop
Reward: -0.03633556514978409
Distance: 7.686745643615723
Next state: tensor([3, 5, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 5, 1], dtype=torch.int32)
Action: down
Reward: 0.013309381902217865
Distance: 7.623081207275391
Next state: tensor([3, 4, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 4, 1], dtype=torch.int32)
Action: end_episode
Reward: -0.09608373790979385
Distance: 7.509771823883057
Next state: tensor([3, 4, 1], dtype=torch.int32)
================================================================================

