Env ID: [264]
================================================================================
Timestep: 0
State: tensor([4, 4, 0], dtype=torch.int32)
Action: up
Reward: -0.06961879879236221
Distance: 7.190695762634277
Next state: tensor([4, 5, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 5, 1], dtype=torch.int32)
Action: pickup
Reward: -0.1361461579799652
Distance: 7.160314559936523
Next state: tensor([4, 5, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 5, 1], dtype=torch.int32)
Action: pickup
Reward: -0.06782922893762589
Distance: 7.196460723876953
Next state: tensor([4, 5, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 5, 1], dtype=torch.int32)
Action: pickup
Reward: -0.06508264690637589
Distance: 7.164289951324463
Next state: tensor([4, 5, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 5, 1], dtype=torch.int32)
Action: right
Reward: -0.14091834425926208
Distance: 7.129372596740723
Next state: tensor([5, 5, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 5
State: tensor([5, 5, 1], dtype=torch.int32)
Action: left
Reward: -0.0013977065682411194
Distance: 7.170290946960449
Next state: tensor([4, 5, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 5, 1], dtype=torch.int32)
Action: drop
Reward: -0.08736763149499893
Distance: 7.071688652038574
Next state: tensor([4, 5, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 5, 1], dtype=torch.int32)
Action: end_episode
Reward: -0.15536698698997498
Distance: 7.059056282043457
Next state: tensor([4, 5, 1], dtype=torch.int32)
================================================================================

