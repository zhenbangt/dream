Env ID: [264]
================================================================================
Timestep: 0
State: tensor([4, 4, 0], dtype=torch.int32)
Action: right
Reward: -0.09927616268396378
Distance: 7.119037628173828
Next state: tensor([5, 4, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1], dtype=torch.int32)
Action: right
Reward: -0.04587993770837784
Distance: 7.118313789367676
Next state: tensor([6, 4, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 2
State: tensor([6, 4, 0], dtype=torch.int32)
Action: left
Reward: -0.2715488374233246
Distance: 7.0641937255859375
Next state: tensor([5, 4, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1], dtype=torch.int32)
Action: ride_bus
Reward: -0.6480551958084106
Distance: 7.235742568969727
Next state: tensor([0, 7, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 4
State: tensor([0, 7, 1], dtype=torch.int32)
Action: end_episode
Reward: 0.0627540573477745
Distance: 7.783797740936279
Next state: tensor([0, 7, 1], dtype=torch.int32)
================================================================================

