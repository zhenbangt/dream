Env ID: [0]
================================================================================
Timestep: 0
State: tensor([4, 4, 0], dtype=torch.int32)
Action: right
Reward: -0.1013561263680458
Distance: 8.119475364685059
Next state: tensor([5, 4, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 1
State: tensor([5, 4, 1], dtype=torch.int32)
Action: left
Reward: -0.09903202205896378
Distance: 8.120831489562988
Next state: tensor([4, 4, 0], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 4, 0], dtype=torch.int32)
Action: right
Reward: 0.1414889395236969
Distance: 8.119863510131836
Next state: tensor([5, 4, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 3
State: tensor([5, 4, 1], dtype=torch.int32)
Action: ride_bus
Reward: 0.9998773336410522
Distance: 7.8783745765686035
Next state: tensor([0, 7, 1], dtype=torch.int32)
================================================================================

================================================================================
Timestep: 4
State: tensor([0, 7, 1], dtype=torch.int32)
Action: end_episode
Reward: -0.432382196187973
Distance: 6.778497219085693
Next state: tensor([0, 7, 1], dtype=torch.int32)
================================================================================

