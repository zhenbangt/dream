Env ID: [12]
================================================================================
Timestep: 0
State: tensor([4, 4, 0, 0])
Action: ride_bus
Reward: -0.0909935012459755
Distance: 16.443359375
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([4, 4, 0, 0])
Action: down
Reward: -0.062131501734256744
Distance: 16.43435287475586
Next state: tensor([4, 3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 3, 1, 0])
Action: down
Reward: -0.07999954372644424
Distance: 16.396484375
Next state: tensor([4, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 0])
Action: noop
Reward: -0.14547118544578552
Distance: 16.376483917236328
Next state: tensor([4, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 0])
Action: drop
Reward: -0.06708679348230362
Distance: 16.421955108642578
Next state: tensor([4, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 0])
Action: up
Reward: -0.0866924300789833
Distance: 16.389041900634766
Next state: tensor([4, 3, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 1, 0])
Action: pickup
Reward: -0.09994468837976456
Distance: 16.375734329223633
Next state: tensor([4, 3, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 3, 1, 0])
Action: up
Reward: -0.1097923293709755
Distance: 16.37567901611328
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 4, 0, 0])
Action: drop
Reward: -0.0861431136727333
Distance: 16.38547134399414
Next state: tensor([4, 4, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 4, 0, 0])
Action: down
Reward: -0.1006084457039833
Distance: 16.371614456176758
Next state: tensor([4, 3, 1, 0])
================================================================================

================================================================================
Timestep: 10
State: tensor([4, 3, 1, 0])
Action: ride_bus
Reward: -0.11596069484949112
Distance: 16.372222900390625
Next state: tensor([8, 7, 1, 0])
================================================================================

================================================================================
Timestep: 11
State: tensor([8, 7, 1, 0])
Action: left
Reward: -0.1298900544643402
Distance: 16.38818359375
Next state: tensor([7, 7, 0, 0])
================================================================================

================================================================================
Timestep: 12
State: tensor([7, 7, 0, 0])
Action: drop
Reward: -0.0762249007821083
Distance: 16.418073654174805
Next state: tensor([7, 7, 0, 0])
================================================================================

================================================================================
Timestep: 13
State: tensor([7, 7, 0, 0])
Action: down
Reward: -0.0977989211678505
Distance: 16.394298553466797
Next state: tensor([7, 6, 0, 0])
================================================================================

================================================================================
Timestep: 14
State: tensor([7, 6, 0, 0])
Action: pickup
Reward: -0.1007457748055458
Distance: 16.39209747314453
Next state: tensor([7, 6, 0, 0])
================================================================================

================================================================================
Timestep: 15
State: tensor([7, 6, 0, 0])
Action: left
Reward: -0.13593634963035583
Distance: 16.39284324645996
Next state: tensor([6, 6, 0, 0])
================================================================================

================================================================================
Timestep: 16
State: tensor([6, 6, 0, 0])
Action: noop
Reward: -0.11987648159265518
Distance: 16.42877960205078
Next state: tensor([6, 6, 0, 0])
================================================================================

================================================================================
Timestep: 17
State: tensor([6, 6, 0, 0])
Action: right
Reward: -0.07332954555749893
Distance: 16.44865608215332
Next state: tensor([7, 6, 0, 0])
================================================================================

================================================================================
Timestep: 18
State: tensor([7, 6, 0, 0])
Action: right
Reward: -0.0875755324959755
Distance: 16.421985626220703
Next state: tensor([8, 6, 0, 0])
================================================================================

================================================================================
Timestep: 19
State: tensor([8, 6, 0, 0])
Action: noop
Reward: -0.12603339552879333
Distance: 16.409561157226562
Next state: tensor([8, 6, 0, 0])
================================================================================

